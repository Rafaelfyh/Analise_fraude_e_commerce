# -*- coding: utf-8 -*-
"""Copy of Analise_Fraude.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1WEVLHr1AHv7HOoQCrVP_rTk63NjZFCMs
"""

from google.colab import drive
drive.mount('/content/drive')

"""# üß† Entendimento do Neg√≥cio

* Problema: identificar fraudes com base em scores e comportamento de compra/documentos.

* Vari√°vel-alvo: fraude
"""

import pandas as pd

csv_url = (
    'https://docs.google.com/spreadsheets/d/'
    '1HqSaTwX5edc-zpO8BQHvMIbndjZFLslxoHLcuUwO5pY'
    '/export?format=csv&gid=2136114581'
)
df = pd.read_csv(csv_url)
df.head()

"""# üîç An√°lise Explorat√≥ria (EDA)"""

# 1) Estat√≠sticas descritivas b√°sicas
print(df.describe())

"""* Verifica√ß√£o de valores ausentes (missing values)"""

import numpy as np

# Fun√ß√£o para verificar valores ausentes
def check_missing_values(df):
    return df.isnull().sum()

# Verificando valores ausentes
missing_values = check_missing_values(df)
print("Valores ausentes:\n", missing_values)

# Imputa√ß√£o de valores ausentes
from sklearn.impute import SimpleImputer

# Para colunas num√©ricas
numerical_cols_with_missing = ['score_2', 'score_3', 'score_4', 'score_6', 'score_9', 'score_10']
imputer_numeric = SimpleImputer(strategy='median')  # Usando a mediana como estrat√©gia de imputa√ß√£o

df[numerical_cols_with_missing] = imputer_numeric.fit_transform(df[numerical_cols_with_missing])

# Para colunas categ√≥ricas
categorical_cols_with_missing = ['pais', 'entrega_doc_2']
imputer_categorical = SimpleImputer(strategy='most_frequent')  # Usando a moda (valor mais frequente)

df[categorical_cols_with_missing] = imputer_categorical.fit_transform(df[categorical_cols_with_missing])

# Verificando os valores ausentes ap√≥s imputa√ß√£o
missing_values_after = df.isnull().sum()
print("\nValores ausentes ap√≥s imputa√ß√£o:\n", missing_values_after)

"""* Imputa√ß√£o num√©rica: Utilizando a mediana para preencher os valores ausentes, pois √© mais robusta contra outliers.

* Imputa√ß√£o categ√≥rica: Usando o valor mais frequente (modo) para preencher os valores ausentes em colunas categ√≥ricas.

* Analise Outliers
"""

from scipy.stats import mstats

# Lista das colunas num√©ricas a serem analisadas
numerical_cols = ['score_2', 'score_3', 'score_4', 'score_6', 'score_9', 'score_10']

# Aplicando winsoriza√ß√£o nas colunas num√©ricas
for col in numerical_cols:
    df[col] = mstats.winsorize(df[col], limits=[0.05, 0.05])  # Winsoriza 5% dos valores em cada extremidade

# Verificando se os valores extremos foram ajustados
print("\nEstat√≠sticas ap√≥s Winsoriza√ß√£o:")
print(df[numerical_cols].describe())

"""* Winsoriza√ß√£o: Os valores extremos (5% dos valores mais baixos e mais altos) s√£o ajustados para os limites dentro desse intervalo. Isso ajuda a evitar que outliers distor√ßam o modelo.

* Resultados ap√≥s Winsoriza√ß√£o:
* As vari√°veis como score_2, score_3, score_6, score_9 e score_10 apresentaram mudan√ßas significativas nos valores m√°ximos e na dispers√£o, alinhando-se melhor aos intervalos definidos.

* O valor m√°ximo de score_6 foi ajustado de 145274 para 162, o que √© uma evid√™ncia de que os outliers mais extremos foram tratadas.

* A distribui√ß√£o de outras vari√°veis, como score_2, tamb√©m mostra uma compress√£o dos valores, o que indica que os outliers foram reduzidos.

#_______________________________________________________#

# üìä An√°lise Univariada
"""

# Estat√≠sticas descritivas
variaveis_univariadas = [
    'score_3', 'valor_compra', 'score_fraude_modelo', 'score_10', 'score_6', 'score_9', 'entrega_doc_1'
]

# Exibe as estat√≠sticas descritivas para as vari√°veis selecionadas
print(df[variaveis_univariadas].describe())

import matplotlib.pyplot as plt
import seaborn as sns

# Gr√°ficos: Histograma + KDE
for col in variaveis_univariadas:
    plt.figure(figsize=(16, 6))

    # Histograma e KDE
    plt.subplot(1, 2, 1)
    sns.histplot(df[col], kde=True, color='skyblue')
    plt.title(f'Distribui√ß√£o de {col}')

    plt.tight_layout()
    plt.show()

import matplotlib.pyplot as plt
import seaborn as sns

# Gr√°ficos: Histograma + KDE
for col in variaveis_univariadas:
    plt.figure(figsize=(16, 6))

    # Histograma e KDE
    plt.subplot(1, 2, 1)
    sns.histplot(df[col], kde=True, color='skyblue')
    plt.title(f'Distribui√ß√£o de {col}')

    plt.tight_layout()
    plt.show()

"""* Resultados - estat√≠sticas descritivas (m√©dia, desvio padr√£o, m√≠nimo, 25%, 50%, 75%, m√°ximo) das vari√°veis-chave.

* Histograma e KDE: O qual mostra a distribui√ß√£o das vari√°veis, tanto com um histograma quanto com a estimativa de densidade (KDE), para entender a forma e a dispers√£o da vari√°vel.

* Boxplot: Exibe a dispers√£o e poss√≠veis outliers nas vari√°veis, facilitando a visualiza√ß√£o de valores extremos.

# üîó An√°lise Bivariada
"""

#  An√°lise Bivariada (Correla√ß√£o com a vari√°vel alvo fraude)
# Seleciona apenas colunas num√©ricas
numeric_cols = df.select_dtypes(include=np.number).columns.tolist()

# Calcula correla√ß√£o com a vari√°vel fraude
correlations = df[numeric_cols].corr()['fraude'].sort_values(ascending=False)

# Exibe as correla√ß√µes (positivas e negativas mais fortes)
print(correlations)

"""# O modelo score_fraude_modelo est√° alinhado com a vari√°vel alvo, como esperado.

H√° ind√≠cios de que:

Compras altas t√™m mais chance de fraude.

N√£o entrega de documentos est√° fortemente associada √† fraude.

Alguns scores operacionais (score_6, score_10, score_9) t√™m correla√ß√£o negativa interessante com a fraude ‚Äî podem indicar comportamento leg√≠timo.

* M√©dias dos scores por classe de fraude
"""

# M√©dia das vari√°veis num√©ricas por grupo de fraude
means_by_class = df.groupby('fraude')[numeric_cols].mean().T
means_by_class.columns = ['N√£o Fraude', 'Fraude']
means_by_class['Diferen√ßa'] = means_by_class['Fraude'] - means_by_class['N√£o Fraude']

print(means_by_class.sort_values(by='Diferen√ßa', ascending=False))

"""# Estrat√©gia

* A n√£o entrega do documento (entrega_doc_1) √© um dos melhores indicadores de fraude at√© agora.

* Scores como score_6, score_10, score_9 t√™m grande poder discriminativo ‚Äî podem ser valiosos em modelos.

* A diferen√ßa de valor_compra tamb√©m √© substancial ‚Äî talvez sirva como feature derivada (e.g. log(valor), categorias de valor).

* Modelo atual (score_fraude_modelo) tem desempenho razo√°vel, mas talvez seja poss√≠vel super√°-lo.
"""

import seaborn as sns
import matplotlib.pyplot as plt

# Lista das vari√°veis mais relevantes
variaveis_chave = ['score_3', 'valor_compra', 'score_fraude_modelo',
                   'entrega_doc_1', 'score_6', 'score_10', 'score_9']

# Estilo
sns.set(style="whitegrid")

# Criar boxplots
for var in variaveis_chave:
    plt.figure(figsize=(8, 5))
    sns.boxplot(x='fraude', y=var, data=df, palette="Set2")
    plt.title(f'Distribui√ß√£o de {var} por Fraude')
    plt.xlabel('Fraude (0 = N√£o, 1 = Sim)')
    plt.ylabel(var)
    plt.tight_layout()
    plt.show()

"""* Teve uma diferen√ßas significativa entre fraude e n√£o fraude: A maioria das vari√°veis mostra diferen√ßas significativas entre as classes, o que sugere que elas podem ser potencialmente √∫teis para prever fraudes.

* As distribui√ß√µes n√£o normais e vari√¢ncias n√£o homog√™neas: Como as distribui√ß√µes n√£o seguem uma normalidade e as vari√¢ncias n√£o s√£o homog√™neas, podemos usar alguns modelos n√£o param√©tricos (como √°rvores de decis√£o, Random Forests ou XGBoost) ou t√©cnicas que n√£o dependem de pressupostos de normalidade.

* Import√¢ncia de vari√°veis como score_fraude_modelo e valor_compra: Algumas vari√°veis, como score_fraude_modelo e valor_compra, apresentam grandes diferen√ßas entre fraude e n√£o fraude, o que as torna importantes para modelagem preditiva.

* Breve resumo:
Signific√¢ncia: Todas as vari√°veis mostraram diferen√ßas significativas entre fraude e n√£o fraude.

# üìà Testes de Hip√≥teses
"""

from scipy.stats import mannwhitneyu

# Lista de vari√°veis para os testes
variaveis_para_teste = [
    'score_3', 'valor_compra', 'score_fraude_modelo', 'score_10', 'score_6', 'score_9', 'entrega_doc_1'
]

# Resultados dos testes de hip√≥teses
testes_hipotese = []

# Executando o teste de Mann-Whitney para cada vari√°vel
for var in variaveis_para_teste:
    # Separando as classes
    fraude = df[df['fraude'] == 1][var]
    nao_fraude = df[df['fraude'] == 0][var]

    # Realizando o teste de Mann-Whitney
    stat, p_valor = mannwhitneyu(fraude, nao_fraude)

    # Armazenando os resultados
    testes_hipotese.append({
        'variavel': var,
        'p_normal_0': nao_fraude.kurtosis(),  # Teste de normalidade para classe 0
        'p_normal_1': fraude.kurtosis(),  # Teste de normalidade para classe 1
        'p_levene': stat,  # estat√≠stica de Mann-Whitney
        'teste': 'Mann-Whitney',
        'p_valor_teste': p_valor
    })

# Exibindo os resultados
resultados_hipotese = pd.DataFrame(testes_hipotese)
print(resultados_hipotese)

"""* Importante Observa√ß√µes:

- Todos os p-valores est√£o abaixo de 0.05 ‚áí rejeitamos H‚ÇÄ, ou seja, h√° diferen√ßas estatisticamente significativas entre os grupos.

- As kurtoses refor√ßam que os dados t√™m distribui√ß√µes diferentes (especialmente valor_compra e score_6), justificando o uso do teste n√£o param√©trico.

# ‚úÖ O que isso diz para o projeto:

- As vari√°veis testadas s√£o bons candidatos para features de modelagem, pois mostram comportamentos estatisticamente diferentes entre classes.

* Teste de hip√≥tese
1. Comparou as distribui√ß√µes das vari√°veis entre as classes
Para cada vari√°vel, o teste avaliou:

‚ÄúA distribui√ß√£o dessa vari√°vel √© significativamente diferente entre os grupos com e sem fraude?‚Äù

2. Evid√™nciou estat√≠stica para apoiar as features

* O resultado mais importante √© o p-valor:

- Sempre se o p_valor_teste < 0.05, significa que h√° evid√™ncia estat√≠stica de que a vari√°vel tem comportamento diferente entre as classes.

- Isso indica que a vari√°vel pode ser √∫til para detectar fraude.

* O teste de hip√≥tese mostrou que todas as vari√°veis analisadas t√™m diferen√ßas estatisticamente significativas entre as classes fraude e n√£o fraude (p-valores muito baixos). Isso indica que essas vari√°veis s√£o boas candidatas para alimentar o modelo, pois ajudam a distinguir entre comportamentos fraudulentos

#___________________________________#
"""

from sklearn.model_selection import train_test_split
from sklearn.metrics import classification_report, roc_auc_score
from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import RandomForestClassifier
from xgboost import XGBClassifier
import pandas as pd

# 1. Selecionar vari√°veis e target
X = df[['score_3', 'valor_compra', 'score_fraude_modelo', 'score_10', 'score_6', 'score_9', 'entrega_doc_1']]
y = df['fraude']

# 2. Divis√£o treino/teste
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, stratify=y, random_state=42)

# 3. Modelos
modelos = {
    'Regress√£o Log√≠stica': LogisticRegression(max_iter=1000),
    'Random Forest': RandomForestClassifier(n_estimators=100, random_state=42),
    'XGBoost': XGBClassifier(use_label_encoder=False, eval_metric='logloss', random_state=42)
}

# 4. Treinar, prever e comparar
resultados = []

for nome, modelo in modelos.items():
    modelo.fit(X_train, y_train)
    y_pred = modelo.predict(X_test)
    y_proba = modelo.predict_proba(X_test)[:,1]

    metrics = classification_report(y_test, y_pred, output_dict=True)
    auc = roc_auc_score(y_test, y_proba)

    resultados.append({
        'Modelo': nome,
        'Acur√°cia': metrics['accuracy'],
        'Precis√£o (fraude)': metrics['1']['precision'],
        'Recall (fraude)': metrics['1']['recall'],
        'F1-Score (fraude)': metrics['1']['f1-score'],
        'AUC-ROC': auc
    })

# Exibir resultados
df_resultados = pd.DataFrame(resultados)
print(df_resultados.sort_values(by='AUC-ROC', ascending=False))

"""* Resultados dos modelos

- ‚úÖ Melhor Modelo: Random Forest
Acur√°cia: 95,17%

F1-Score para fraude: 0.19 (melhor equil√≠brio entre precis√£o e recall)

AUC-ROC: 0.81 (classifica√ß√£o geral boa)

- üîç Resultados mostram:
Todos os modelos acertam bem o ‚Äún√£o fraude‚Äù (explica a alta acur√°cia)

- Random Forest teve o melhor desempenho geral para detectar fraude, com melhor recall, precis√£o e F1.

- Log√≠stica nao teve um bom recall (0.005) ‚Äì ou seja, quase n√£o identificou fraudes.

- XGBoost foi muito bom tamb√©m, s√≥ levemente atr√°s do Random Forest.
"""

from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay
import matplotlib.pyplot as plt

# Treinando os modelos
modelo_log = LogisticRegression(random_state=42)
modelo_log.fit(X_train, y_train)

modelo_rf = RandomForestClassifier(random_state=42)
modelo_rf.fit(X_train, y_train)

modelo_xgb = XGBClassifier(random_state=42)
modelo_xgb.fit(X_train, y_train)

# Lista de modelos e seus nomes
modelos = [
    ('Regress√£o Log√≠stica', modelo_log),
    ('Random Forest', modelo_rf),
    ('XGBoost', modelo_xgb)
]

# Plot das matrizes de confus√£o
plt.figure(figsize=(18, 5))

for i, (nome, modelo) in enumerate(modelos):
    # Previs√µes
    y_pred = modelo.predict(X_test)

    # Matriz de confus√£o
    cm = confusion_matrix(y_test, y_pred)

    # Plot
    plt.subplot(1, 3, i+1)
    disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=modelo.classes_)
    disp.plot(ax=plt.gca(), values_format='d')
    plt.title(nome)

plt.tight_layout()
plt.show()

"""* Esses sao os resultados de falso negativo (fraude n√°o detectada) Como apresentado o Xgboost teve menor numero de fraudes

# Teste de hiperparamentros
"""

# Balanceamento da base com SMOTE
from imblearn.over_sampling import SMOTE

# Aplicando o SMOTE
smote = SMOTE(random_state=42)
X_train_bal, y_train_bal = smote.fit_resample(X_train, y_train)

# Verificando o balanceamento
print("Distribui√ß√£o ap√≥s SMOTE:")
print(y_train_bal.value_counts())

# Re-treinar Random Forest e XGBoost com dados balanceados

from sklearn.ensemble import RandomForestClassifier
from xgboost import XGBClassifier

# Reinstanciando e treinando os modelos
modelo_rf_bal = RandomForestClassifier(random_state=42)
modelo_rf_bal.fit(X_train_bal, y_train_bal)

modelo_xgb_bal = XGBClassifier(random_state=42, use_label_encoder=False, eval_metric='logloss')
modelo_xgb_bal.fit(X_train_bal, y_train_bal)

# Avaliar desempenho dos modelos balanceados
from sklearn.metrics import classification_report, roc_auc_score

modelos_balanceados = {
    'Random Forest (SMOTE)': modelo_rf_bal,
    'XGBoost (SMOTE)': modelo_xgb_bal
}

for nome, modelo in modelos_balanceados.items():
    y_pred = modelo.predict(X_test)
    print(f"\nModelo: {nome}")
    print(classification_report(y_test, y_pred, digits=4))

    # AUC
    if hasattr(modelo, "predict_proba"):
        y_prob = modelo.predict_proba(X_test)[:, 1]
    else:
        y_prob = modelo.decision_function(X_test)
    auc = roc_auc_score(y_test, y_prob)
    print("AUC-ROC:", round(auc, 4))

from imblearn.over_sampling import SMOTE
from sklearn.model_selection import train_test_split

# Separando treino e teste antes de aplicar SMOTE
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, stratify=y, random_state=42)

# Aplicando SMOTE no conjunto de treino
smote = SMOTE(random_state=42)
X_train_res, y_train_res = smote.fit_resample(X_train, y_train)

from sklearn.ensemble import RandomForestClassifier
from xgboost import XGBClassifier

# Treinando modelos com dados balanceados (SMOTE)
modelo_rf_smote = RandomForestClassifier(random_state=42)
modelo_rf_smote.fit(X_train_res, y_train_res)

modelo_xgb_smote = XGBClassifier(random_state=42)
modelo_xgb_smote.fit(X_train_res, y_train_res)

from sklearn.ensemble import RandomForestClassifier
from xgboost import XGBClassifier

# Random Forest com SMOTE
modelo_rf_smote = RandomForestClassifier(random_state=42)
modelo_rf_smote.fit(X_train_res, y_train_res)

# XGBoost com SMOTE
modelo_xgb_smote = XGBClassifier(use_label_encoder=False, eval_metric='logloss', random_state=42)
modelo_xgb_smote.fit(X_train_res, y_train_res)

from sklearn.metrics import classification_report, roc_auc_score, confusion_matrix, ConfusionMatrixDisplay
import matplotlib.pyplot as plt

# Lista de modelos treinados com SMOTE
modelos_smote = [
    ('Random Forest (SMOTE)', modelo_rf_smote),
    ('XGBoost (SMOTE)', modelo_xgb_smote)
]

# Avalia√ß√£o dos modelos
for nome, modelo in modelos_smote:
    print(f"\nModelo: {nome}")

    # Previs√µes
    y_pred = modelo.predict(X_test)
    y_prob = modelo.predict_proba(X_test)[:, 1]  # Probabilidades para AUC-ROC

    # Relat√≥rio de classifica√ß√£o
    print(classification_report(y_test, y_pred, digits=4))

    # AUC-ROC
    auc = roc_auc_score(y_test, y_prob)
    print(f"AUC-ROC: {auc:.4f}")

    # Matriz de confus√£o
    cm = confusion_matrix(y_test, y_pred)
    disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=modelo.classes_)
    disp.plot(cmap=plt.cm.Blues)
    plt.title(nome)
    plt.show()

"""* XGBoost teve ligeiramente melhor recall de fraudes, mas menor precis√£o.

Random Forest teve melhor equil√≠brio geral (AUC, F1 e acur√°cia).

A diferen√ßa de acertos totais √© pequena.

* üí° Se o foco √© detectar mais fraudes mesmo errando um pouco mais (alto recall), o XGBoost pode ser preferido.
Se o foco √© ter uma performance mais equilibrada, o Random Forest se destaca.

* An√°lise do Trade-off:
* Precision vs. Recall: Embora a precision para a classe "n√£o fraude" seja muito boa, a recall da classe "fraude" precisa ser muito melhorada. Ou seja, o modelo √© conservador (n√£o identifica muitas fraudes) e perde a chance de bloquear muitas transa√ß√µes fraudulentas.

* Custo das fraudes: Falsos negativos (fraudes n√£o identificadas) s√£o mais cr√≠ticos do que falsos positivos (compra leg√≠tima erradamente marcada como fraude). O preju√≠zo por fraude aprovada √© 100% do valor da compra, ent√£o, precisamos otimizar os modelos para identificar mais fraudes, mesmo que isso signifique reduzir a precis√£o.

# Ajuste do cutoff de decis√£o: Uma abordagem para melhorar o recall de fraudes seria ajustar o cutoff de probabilidade.
"""

import numpy as np
import matplotlib.pyplot as plt

# 1) Montar o df_test com tudo que precisamos
df_test = X_test.copy()
df_test['fraude'] = y_test.values
# Traga o valor_compra do df original pelo mesmo √≠ndice
df_test['valor_compra'] = df.loc[X_test.index, 'valor_compra']
# Probabilidade de fraude segundo o modelo balanceado
df_test['prob_rf'] = modelo_rf_smote.predict_proba(X_test)[:, 1]

# 2) Fun√ß√£o de lucro l√≠quido
def lucro_liquido(cutoff):
    aprovadas = df_test[df_test['prob_rf'] < cutoff]
    ganho = aprovadas.loc[aprovadas['fraude'] == 0, 'valor_compra'].sum() * 0.10
    perda = aprovadas.loc[aprovadas['fraude'] == 1, 'valor_compra'].sum()
    return ganho - perda

# 3) Simular lucro para uma grade de cutoffs de 0 a 1
thresholds = np.linspace(0, 1, 101)
profits = [lucro_liquido(t) for t in thresholds]

# 4) Encontrar o melhor cutoff
best_i = int(np.argmax(profits))
best_cutoff = thresholds[best_i]
best_profit = profits[best_i]

print(f"üîé Melhor cutoff: {best_cutoff:.2f}")
print(f"üí∞ Lucro l√≠quido estimado: R$ {best_profit:,.2f}")

# 5) Plotar Lucro vs Cutoff
plt.figure(figsize=(8,5))
plt.plot(thresholds, profits, marker='o')
plt.axvline(best_cutoff, color='red', linestyle='--', label=f"Cutoff √≥timo ({best_cutoff:.2f})")
plt.title('Lucro L√≠quido vs. Cutoff de Probabilidade de Fraude')
plt.xlabel('Cutoff de Probabilidade')
plt.ylabel('Lucro L√≠quido (R$)')
plt.legend()
plt.grid(True)
plt.show()

"""* Regra de decis√£o: Ao bloquear todas as transa√ß√µes em que a probabilidade de fraude ‚â•¬†0.44, voc√™ maximiza o retorno financeiro.
* Trade‚Äëoff: Esse ponto reflete um equil√≠brio em que voc√™ aprende a aceitar algumas fraudes (para n√£o perder compras leg√≠timas demais), mas bloqueia fraudes suficientes para gerar o maior lucro l√≠quido.
"""

#classificando as transa√ß√µes com base na probabilidade de fraude,
y_proba = modelo_rf_smote.predict_proba(X)[:,1]
aprovar = (y_proba < 0.44)

"""# üß† Insights Finais

- Vari√°veis mais discriminativas

- Entrega de documentos (entrega_doc_1): aus√™ncia de documento aumenta fortemente a probabilidade de fraude.

- Scores operacionais (score_6, score_9, score_10, score_3): perfis de comportamento (‚Äúnotas‚Äù de confiabilidade) mostram diferen√ßas significativas entre fraudadores e clientes leg√≠timos.

- Valor da compra: transa√ß√µes fraudulentas tendem a ter ticket m√©dio muito maior.

- Modelagem e performance

- Random Forest (SMOTE): melhor equil√≠brio geral (AUC‚ÄëROC 0.7475, Recall fraude 35.9%).

- XGBoost (SMOTE): ligeiramente maior recall (38.7%) mas AUC‚ÄëROC um pouco menor (0.7379).

- Regress√£o Log√≠stica: baixa capacidade de capturar fraudes (recall <¬†1%).

Otimiza√ß√£o para o neg√≥cio

Cutoff √≥timo de 0.44 sobre a probabilidade de fraude do Random Forest (SMOTE), que maximiza o lucro l√≠quido em R$¬†68.525,43 no conjunto de teste.

Isso ajuda a decidir equilibra aprovar compras leg√≠timas (ganho de 10%) e bloquear fraudes (evitar perda de 100%).

#_________________________________________________________________________________________________________________________________________________________#

# üíº Sugest√£o ao Neg√≥cio

* Implementar o modelo em produ√ß√£o

Score em tempo real via API: para cada nova transa√ß√£o, calcular prob_fraude = modelo.predict_proba(...)[:,1].

Regra de neg√≥cio: aprovar se prob_fraude < 0.44; caso contr√°rio, bloquear ou escalonar para an√°lise manual.

* Monitoramento cont√≠nuo

M√©tricas operacionais: acompanhar diariamente recall de fraude, ratio de aprova√ß√µes bloqueadas, receita gerada.

Data‚Äëdrift: monitorar distribui√ß√£o de features (scores, valor_compra, entrega_doc_) para detectar mudan√ßas no perfil de fraude.

* Ciclo de retroalimenta√ß√£o

Feedback loop: incorporar rapidamente o resultado real (confirmado como fraude ou n√£o) para re-treinar o modelo periodicamente.

- A/B testing de cutoffs: testar limiares ligeiramente diferentes (por exemplo, 0.40, 0.45) em grupos de controle para validar o cutoff √≥timo em produ√ß√£o.

* Aprimorar features e cobertura

- Explorar novas vari√°veis derivadas dos scores (combina√ß√µes, m√©dias ponderadas).

- Incluir dados comportamentais (tempo de navega√ß√£o, device fingerprinting) se dispon√≠veis.

# Governan√ßa e compliance

Documentar todo o fluxo de dados e modelo para auditoria.

Garantir explicabilidade usando SHAP para justificar bloqueios de transa√ß√µes, atendendo a requisitos regulat√≥rios.

# ‚úÖ Pr√≥ximos passos recomendados:
* Testar estabilidade do cutoff em diferentes splits ou per√≠odos (time split).

* Monitorar performance no ambiente real, ajustando se houver drift de dados.

* Avaliar impacto de novas features para tentar elevar ainda mais esse lucro.

# üöÄ Deploy

- Infraestrutura: containerizar o modelo (Docker) e exp√¥-lo via REST API (FastAPI ou Flask)

- Lat√™ncia: garantir infer√™ncia em 200 ms por transa√ß√£o, priorizando predi√ß√£o em batch e em tempo real, se necess√°rio

- Escalabilidade: usar orquestradores (Kubernetes) para suportar picos de demanda

- Logging e alertas: capturar decis√µes, probabilidades, contexto da transa√ß√£o e acionar alertas para aumento s√∫bito de fraudes.
"""

