{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6_cOlMvEbeN0"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# üß† Entendimento do Neg√≥cio"
      ],
      "metadata": {
        "id": "3nCACJ4kbiMp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Problema: identificar fraudes com base em scores e comportamento de compra/documentos.\n",
        "\n",
        "* Vari√°vel-alvo: fraude"
      ],
      "metadata": {
        "id": "T5YA9_Zirttb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "csv_url = (\n",
        "    'https://docs.google.com/spreadsheets/d/'\n",
        "    '1HqSaTwX5edc-zpO8BQHvMIbndjZFLslxoHLcuUwO5pY'\n",
        "    '/export?format=csv&gid=2136114581'\n",
        ")\n",
        "df = pd.read_csv(csv_url)\n",
        "df.head()\n"
      ],
      "metadata": {
        "id": "1wVHxs3klIiv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# üîç An√°lise Explorat√≥ria (EDA)"
      ],
      "metadata": {
        "id": "yMxeRCpMlnmd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# 1) Estat√≠sticas descritivas b√°sicas\n",
        "print(df.describe())"
      ],
      "metadata": {
        "id": "QI5P1SyEk51C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Verifica√ß√£o de valores ausentes (missing values)"
      ],
      "metadata": {
        "id": "CR2q0tR8l2ir"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# Fun√ß√£o para verificar valores ausentes\n",
        "def check_missing_values(df):\n",
        "    return df.isnull().sum()\n",
        "\n",
        "# Verificando valores ausentes\n",
        "missing_values = check_missing_values(df)\n",
        "print(\"Valores ausentes:\\n\", missing_values)"
      ],
      "metadata": {
        "id": "IiBgVPMtl2OR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Imputa√ß√£o de valores ausentes\n",
        "from sklearn.impute import SimpleImputer\n",
        "\n",
        "# Para colunas num√©ricas\n",
        "numerical_cols_with_missing = ['score_2', 'score_3', 'score_4', 'score_6', 'score_9', 'score_10']\n",
        "imputer_numeric = SimpleImputer(strategy='median')  # Usando a mediana como estrat√©gia de imputa√ß√£o\n",
        "\n",
        "df[numerical_cols_with_missing] = imputer_numeric.fit_transform(df[numerical_cols_with_missing])\n",
        "\n",
        "# Para colunas categ√≥ricas\n",
        "categorical_cols_with_missing = ['pais', 'entrega_doc_2']\n",
        "imputer_categorical = SimpleImputer(strategy='most_frequent')  # Usando a moda (valor mais frequente)\n",
        "\n",
        "df[categorical_cols_with_missing] = imputer_categorical.fit_transform(df[categorical_cols_with_missing])\n",
        "\n",
        "# Verificando os valores ausentes ap√≥s imputa√ß√£o\n",
        "missing_values_after = df.isnull().sum()\n",
        "print(\"\\nValores ausentes ap√≥s imputa√ß√£o:\\n\", missing_values_after)\n"
      ],
      "metadata": {
        "id": "X9kvEoLmlewx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Imputa√ß√£o num√©rica: Utilizando a mediana para preencher os valores ausentes, pois √© mais robusta contra outliers.\n",
        "\n",
        "* Imputa√ß√£o categ√≥rica: Usando o valor mais frequente (modo) para preencher os valores ausentes em colunas categ√≥ricas."
      ],
      "metadata": {
        "id": "Sp8ZkMELmjPF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Analise Outliers\n",
        "\n"
      ],
      "metadata": {
        "id": "Vme7SySMndBR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy.stats import mstats\n",
        "\n",
        "# Lista das colunas num√©ricas a serem analisadas\n",
        "numerical_cols = ['score_2', 'score_3', 'score_4', 'score_6', 'score_9', 'score_10']\n",
        "\n",
        "# Aplicando winsoriza√ß√£o nas colunas num√©ricas\n",
        "for col in numerical_cols:\n",
        "    df[col] = mstats.winsorize(df[col], limits=[0.05, 0.05])  # Winsoriza 5% dos valores em cada extremidade\n",
        "\n",
        "# Verificando se os valores extremos foram ajustados\n",
        "print(\"\\nEstat√≠sticas ap√≥s Winsoriza√ß√£o:\")\n",
        "print(df[numerical_cols].describe())\n"
      ],
      "metadata": {
        "id": "iwq6pvitmeYF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Winsoriza√ß√£o: Os valores extremos (5% dos valores mais baixos e mais altos) s√£o ajustados para os limites dentro desse intervalo. Isso ajuda a evitar que outliers distor√ßam o modelo."
      ],
      "metadata": {
        "id": "p53uHpBsnD7k"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Resultados ap√≥s Winsoriza√ß√£o:\n",
        "* As vari√°veis como score_2, score_3, score_6, score_9 e score_10 apresentaram mudan√ßas significativas nos valores m√°ximos e na dispers√£o, alinhando-se melhor aos intervalos definidos.\n",
        "\n",
        "* O valor m√°ximo de score_6 foi ajustado de 145274 para 162, o que √© uma evid√™ncia de que os outliers mais extremos foram tratadas.\n",
        "\n",
        "* A distribui√ß√£o de outras vari√°veis, como score_2, tamb√©m mostra uma compress√£o dos valores, o que indica que os outliers foram reduzidos."
      ],
      "metadata": {
        "id": "f_bL96-hnTvL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#_______________________________________________________#"
      ],
      "metadata": {
        "id": "q6H1BLKuoK2h"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# üìä An√°lise Univariada"
      ],
      "metadata": {
        "id": "8KxaXzy2tQBc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Estat√≠sticas descritivas\n",
        "variaveis_univariadas = [\n",
        "    'score_3', 'valor_compra', 'score_fraude_modelo', 'score_10', 'score_6', 'score_9', 'entrega_doc_1'\n",
        "]\n",
        "\n",
        "# Exibe as estat√≠sticas descritivas para as vari√°veis selecionadas\n",
        "print(df[variaveis_univariadas].describe())\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "JWzqQjV9tlLj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Gr√°ficos: Histograma + KDE\n",
        "for col in variaveis_univariadas:\n",
        "    plt.figure(figsize=(16, 6))\n",
        "\n",
        "    # Histograma e KDE\n",
        "    plt.subplot(1, 2, 1)\n",
        "    sns.histplot(df[col], kde=True, color='skyblue')\n",
        "    plt.title(f'Distribui√ß√£o de {col}')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n"
      ],
      "metadata": {
        "id": "fmmXijHPuRy-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Gr√°ficos: Histograma + KDE\n",
        "for col in variaveis_univariadas:\n",
        "    plt.figure(figsize=(16, 6))\n",
        "\n",
        "    # Histograma e KDE\n",
        "    plt.subplot(1, 2, 1)\n",
        "    sns.histplot(df[col], kde=True, color='skyblue')\n",
        "    plt.title(f'Distribui√ß√£o de {col}')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n"
      ],
      "metadata": {
        "id": "TIuvshgJuCMy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Resultados - estat√≠sticas descritivas (m√©dia, desvio padr√£o, m√≠nimo, 25%, 50%, 75%, m√°ximo) das vari√°veis-chave.\n",
        "\n",
        "* Histograma e KDE: O qual mostra a distribui√ß√£o das vari√°veis, tanto com um histograma quanto com a estimativa de densidade (KDE), para entender a forma e a dispers√£o da vari√°vel.\n",
        "\n",
        "* Boxplot: Exibe a dispers√£o e poss√≠veis outliers nas vari√°veis, facilitando a visualiza√ß√£o de valores extremos.\n"
      ],
      "metadata": {
        "id": "v6zouYv1tqTh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        " # üîó An√°lise Bivariada\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "8wWaXAnuoPPw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#  An√°lise Bivariada (Correla√ß√£o com a vari√°vel alvo fraude)\n",
        "# Seleciona apenas colunas num√©ricas\n",
        "numeric_cols = df.select_dtypes(include=np.number).columns.tolist()\n",
        "\n",
        "# Calcula correla√ß√£o com a vari√°vel fraude\n",
        "correlations = df[numeric_cols].corr()['fraude'].sort_values(ascending=False)\n",
        "\n",
        "# Exibe as correla√ß√µes (positivas e negativas mais fortes)\n",
        "print(correlations)\n"
      ],
      "metadata": {
        "id": "oQrVCRcsm8iS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# O modelo score_fraude_modelo est√° alinhado com a vari√°vel alvo, como esperado.\n",
        "\n",
        "H√° ind√≠cios de que:\n",
        "\n",
        "Compras altas t√™m mais chance de fraude.\n",
        "\n",
        "N√£o entrega de documentos est√° fortemente associada √† fraude.\n",
        "\n",
        "Alguns scores operacionais (score_6, score_10, score_9) t√™m correla√ß√£o negativa interessante com a fraude ‚Äî podem indicar comportamento leg√≠timo."
      ],
      "metadata": {
        "id": "QykrdqAxo6n6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* M√©dias dos scores por classe de fraude"
      ],
      "metadata": {
        "id": "o1qB_ULLob6z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# M√©dia das vari√°veis num√©ricas por grupo de fraude\n",
        "means_by_class = df.groupby('fraude')[numeric_cols].mean().T\n",
        "means_by_class.columns = ['N√£o Fraude', 'Fraude']\n",
        "means_by_class['Diferen√ßa'] = means_by_class['Fraude'] - means_by_class['N√£o Fraude']\n",
        "\n",
        "print(means_by_class.sort_values(by='Diferen√ßa', ascending=False))\n"
      ],
      "metadata": {
        "id": "wVCXlUZyoXVJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Estrat√©gia\n",
        "\n",
        "* A n√£o entrega do documento (entrega_doc_1) √© um dos melhores indicadores de fraude at√© agora.\n",
        "\n",
        "* Scores como score_6, score_10, score_9 t√™m grande poder discriminativo ‚Äî podem ser valiosos em modelos.\n",
        "\n",
        "* A diferen√ßa de valor_compra tamb√©m √© substancial ‚Äî talvez sirva como feature derivada (e.g. log(valor), categorias de valor).\n",
        "\n",
        "* Modelo atual (score_fraude_modelo) tem desempenho razo√°vel, mas talvez seja poss√≠vel super√°-lo."
      ],
      "metadata": {
        "id": "I-ixogRppOhw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Lista das vari√°veis mais relevantes\n",
        "variaveis_chave = ['score_3', 'valor_compra', 'score_fraude_modelo',\n",
        "                   'entrega_doc_1', 'score_6', 'score_10', 'score_9']\n",
        "\n",
        "# Estilo\n",
        "sns.set(style=\"whitegrid\")\n",
        "\n",
        "# Criar boxplots\n",
        "for var in variaveis_chave:\n",
        "    plt.figure(figsize=(8, 5))\n",
        "    sns.boxplot(x='fraude', y=var, data=df, palette=\"Set2\")\n",
        "    plt.title(f'Distribui√ß√£o de {var} por Fraude')\n",
        "    plt.xlabel('Fraude (0 = N√£o, 1 = Sim)')\n",
        "    plt.ylabel(var)\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n"
      ],
      "metadata": {
        "id": "z0_YlTlSoeUa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Teve uma diferen√ßas significativa entre fraude e n√£o fraude: A maioria das vari√°veis mostra diferen√ßas significativas entre as classes, o que sugere que elas podem ser potencialmente √∫teis para prever fraudes.\n",
        "\n",
        "* As distribui√ß√µes n√£o normais e vari√¢ncias n√£o homog√™neas: Como as distribui√ß√µes n√£o seguem uma normalidade e as vari√¢ncias n√£o s√£o homog√™neas, podemos usar alguns modelos n√£o param√©tricos (como √°rvores de decis√£o, Random Forests ou XGBoost) ou t√©cnicas que n√£o dependem de pressupostos de normalidade.\n",
        "\n",
        "* Import√¢ncia de vari√°veis como score_fraude_modelo e valor_compra: Algumas vari√°veis, como score_fraude_modelo e valor_compra, apresentam grandes diferen√ßas entre fraude e n√£o fraude, o que as torna importantes para modelagem preditiva.\n",
        "\n",
        "* Breve resumo:\n",
        "Signific√¢ncia: Todas as vari√°veis mostraram diferen√ßas significativas entre fraude e n√£o fraude.\n",
        "\n"
      ],
      "metadata": {
        "id": "e7uHcL-vupvj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# üìà Testes de Hip√≥teses"
      ],
      "metadata": {
        "id": "Yp991D_bxcbP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy.stats import mannwhitneyu\n",
        "\n",
        "# Lista de vari√°veis para os testes\n",
        "variaveis_para_teste = [\n",
        "    'score_3', 'valor_compra', 'score_fraude_modelo', 'score_10', 'score_6', 'score_9', 'entrega_doc_1'\n",
        "]\n",
        "\n",
        "# Resultados dos testes de hip√≥teses\n",
        "testes_hipotese = []\n",
        "\n",
        "# Executando o teste de Mann-Whitney para cada vari√°vel\n",
        "for var in variaveis_para_teste:\n",
        "    # Separando as classes\n",
        "    fraude = df[df['fraude'] == 1][var]\n",
        "    nao_fraude = df[df['fraude'] == 0][var]\n",
        "\n",
        "    # Realizando o teste de Mann-Whitney\n",
        "    stat, p_valor = mannwhitneyu(fraude, nao_fraude)\n",
        "\n",
        "    # Armazenando os resultados\n",
        "    testes_hipotese.append({\n",
        "        'variavel': var,\n",
        "        'p_normal_0': nao_fraude.kurtosis(),  # Teste de normalidade para classe 0\n",
        "        'p_normal_1': fraude.kurtosis(),  # Teste de normalidade para classe 1\n",
        "        'p_levene': stat,  # estat√≠stica de Mann-Whitney\n",
        "        'teste': 'Mann-Whitney',\n",
        "        'p_valor_teste': p_valor\n",
        "    })\n",
        "\n",
        "# Exibindo os resultados\n",
        "resultados_hipotese = pd.DataFrame(testes_hipotese)\n",
        "print(resultados_hipotese)\n"
      ],
      "metadata": {
        "id": "94-My68zqRaj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Importante Observa√ß√µes:\n",
        "\n",
        "- Todos os p-valores est√£o abaixo de 0.05 ‚áí rejeitamos H‚ÇÄ, ou seja, h√° diferen√ßas estatisticamente significativas entre os grupos.\n",
        "\n",
        "- As kurtoses refor√ßam que os dados t√™m distribui√ß√µes diferentes (especialmente valor_compra e score_6), justificando o uso do teste n√£o param√©trico."
      ],
      "metadata": {
        "id": "mb6HJLmA2KrQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ‚úÖ O que isso diz para o projeto:\n",
        "\n",
        "- As vari√°veis testadas s√£o bons candidatos para features de modelagem, pois mostram comportamentos estatisticamente diferentes entre classes.\n",
        "\n"
      ],
      "metadata": {
        "id": "gm4MCTnj2lCh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Teste de hip√≥tese\n",
        "1. Comparou as distribui√ß√µes das vari√°veis entre as classes\n",
        "Para cada vari√°vel, o teste avaliou:\n",
        "\n",
        "‚ÄúA distribui√ß√£o dessa vari√°vel √© significativamente diferente entre os grupos com e sem fraude?‚Äù\n",
        "\n",
        "2. Evid√™nciou estat√≠stica para apoiar as features\n",
        "\n",
        "* O resultado mais importante √© o p-valor:\n",
        "\n",
        "- Sempre se o p_valor_teste < 0.05, significa que h√° evid√™ncia estat√≠stica de que a vari√°vel tem comportamento diferente entre as classes.\n",
        "\n",
        "- Isso indica que a vari√°vel pode ser √∫til para detectar fraude.\n",
        "\n"
      ],
      "metadata": {
        "id": "z7hEgR2m3ACu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* O teste de hip√≥tese mostrou que todas as vari√°veis analisadas t√™m diferen√ßas estatisticamente significativas entre as classes fraude e n√£o fraude (p-valores muito baixos). Isso indica que essas vari√°veis s√£o boas candidatas para alimentar o modelo, pois ajudam a distinguir entre comportamentos fraudulentos"
      ],
      "metadata": {
        "id": "0hGDv5G64CB3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#___________________________________#"
      ],
      "metadata": {
        "id": "7HLLznn05GzX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report, roc_auc_score\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from xgboost import XGBClassifier\n",
        "import pandas as pd\n",
        "\n",
        "# 1. Selecionar vari√°veis e target\n",
        "X = df[['score_3', 'valor_compra', 'score_fraude_modelo', 'score_10', 'score_6', 'score_9', 'entrega_doc_1']]\n",
        "y = df['fraude']\n",
        "\n",
        "# 2. Divis√£o treino/teste\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, stratify=y, random_state=42)\n",
        "\n",
        "# 3. Modelos\n",
        "modelos = {\n",
        "    'Regress√£o Log√≠stica': LogisticRegression(max_iter=1000),\n",
        "    'Random Forest': RandomForestClassifier(n_estimators=100, random_state=42),\n",
        "    'XGBoost': XGBClassifier(use_label_encoder=False, eval_metric='logloss', random_state=42)\n",
        "}\n",
        "\n",
        "# 4. Treinar, prever e comparar\n",
        "resultados = []\n",
        "\n",
        "for nome, modelo in modelos.items():\n",
        "    modelo.fit(X_train, y_train)\n",
        "    y_pred = modelo.predict(X_test)\n",
        "    y_proba = modelo.predict_proba(X_test)[:,1]\n",
        "\n",
        "    metrics = classification_report(y_test, y_pred, output_dict=True)\n",
        "    auc = roc_auc_score(y_test, y_proba)\n",
        "\n",
        "    resultados.append({\n",
        "        'Modelo': nome,\n",
        "        'Acur√°cia': metrics['accuracy'],\n",
        "        'Precis√£o (fraude)': metrics['1']['precision'],\n",
        "        'Recall (fraude)': metrics['1']['recall'],\n",
        "        'F1-Score (fraude)': metrics['1']['f1-score'],\n",
        "        'AUC-ROC': auc\n",
        "    })\n",
        "\n",
        "# Exibir resultados\n",
        "df_resultados = pd.DataFrame(resultados)\n",
        "print(df_resultados.sort_values(by='AUC-ROC', ascending=False))\n"
      ],
      "metadata": {
        "id": "BkLCq37z11bv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Resultados dos modelos\n",
        "\n",
        "- ‚úÖ Melhor Modelo: Random Forest\n",
        "Acur√°cia: 95,17%\n",
        "\n",
        "F1-Score para fraude: 0.19 (melhor equil√≠brio entre precis√£o e recall)\n",
        "\n",
        "AUC-ROC: 0.81 (classifica√ß√£o geral boa)\n",
        "\n",
        "- üîç Resultados mostram:\n",
        "Todos os modelos acertam bem o ‚Äún√£o fraude‚Äù (explica a alta acur√°cia)\n",
        "\n",
        "- Random Forest teve o melhor desempenho geral para detectar fraude, com melhor recall, precis√£o e F1.\n",
        "\n",
        "- Log√≠stica nao teve um bom recall (0.005) ‚Äì ou seja, quase n√£o identificou fraudes.\n",
        "\n",
        "- XGBoost foi muito bom tamb√©m, s√≥ levemente atr√°s do Random Forest."
      ],
      "metadata": {
        "id": "BAu-Kthb5QFb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Treinando os modelos\n",
        "modelo_log = LogisticRegression(random_state=42)\n",
        "modelo_log.fit(X_train, y_train)\n",
        "\n",
        "modelo_rf = RandomForestClassifier(random_state=42)\n",
        "modelo_rf.fit(X_train, y_train)\n",
        "\n",
        "modelo_xgb = XGBClassifier(random_state=42)\n",
        "modelo_xgb.fit(X_train, y_train)\n",
        "\n",
        "# Lista de modelos e seus nomes\n",
        "modelos = [\n",
        "    ('Regress√£o Log√≠stica', modelo_log),\n",
        "    ('Random Forest', modelo_rf),\n",
        "    ('XGBoost', modelo_xgb)\n",
        "]\n",
        "\n",
        "# Plot das matrizes de confus√£o\n",
        "plt.figure(figsize=(18, 5))\n",
        "\n",
        "for i, (nome, modelo) in enumerate(modelos):\n",
        "    # Previs√µes\n",
        "    y_pred = modelo.predict(X_test)\n",
        "\n",
        "    # Matriz de confus√£o\n",
        "    cm = confusion_matrix(y_test, y_pred)\n",
        "\n",
        "    # Plot\n",
        "    plt.subplot(1, 3, i+1)\n",
        "    disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=modelo.classes_)\n",
        "    disp.plot(ax=plt.gca(), values_format='d')\n",
        "    plt.title(nome)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n"
      ],
      "metadata": {
        "id": "JgPMBl4U4r4T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Esses sao os resultados de falso negativo (fraude n√°o detectada) Como apresentado o Xgboost teve menor numero de fraudes"
      ],
      "metadata": {
        "id": "AVhHlRZ-Z0x1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Teste de hiperparamentros"
      ],
      "metadata": {
        "id": "CijJpoP7aUgK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Balanceamento da base com SMOTE\n",
        "from imblearn.over_sampling import SMOTE\n",
        "\n",
        "# Aplicando o SMOTE\n",
        "smote = SMOTE(random_state=42)\n",
        "X_train_bal, y_train_bal = smote.fit_resample(X_train, y_train)\n",
        "\n",
        "# Verificando o balanceamento\n",
        "print(\"Distribui√ß√£o ap√≥s SMOTE:\")\n",
        "print(y_train_bal.value_counts())\n"
      ],
      "metadata": {
        "id": "aFVXyqUT_B1X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Re-treinar Random Forest e XGBoost com dados balanceados\n",
        "\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from xgboost import XGBClassifier\n",
        "\n",
        "# Reinstanciando e treinando os modelos\n",
        "modelo_rf_bal = RandomForestClassifier(random_state=42)\n",
        "modelo_rf_bal.fit(X_train_bal, y_train_bal)\n",
        "\n",
        "modelo_xgb_bal = XGBClassifier(random_state=42, use_label_encoder=False, eval_metric='logloss')\n",
        "modelo_xgb_bal.fit(X_train_bal, y_train_bal)\n"
      ],
      "metadata": {
        "id": "SMDH4T2uaaji"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Avaliar desempenho dos modelos balanceados\n",
        "from sklearn.metrics import classification_report, roc_auc_score\n",
        "\n",
        "modelos_balanceados = {\n",
        "    'Random Forest (SMOTE)': modelo_rf_bal,\n",
        "    'XGBoost (SMOTE)': modelo_xgb_bal\n",
        "}\n",
        "\n",
        "for nome, modelo in modelos_balanceados.items():\n",
        "    y_pred = modelo.predict(X_test)\n",
        "    print(f\"\\nModelo: {nome}\")\n",
        "    print(classification_report(y_test, y_pred, digits=4))\n",
        "\n",
        "    # AUC\n",
        "    if hasattr(modelo, \"predict_proba\"):\n",
        "        y_prob = modelo.predict_proba(X_test)[:, 1]\n",
        "    else:\n",
        "        y_prob = modelo.decision_function(X_test)\n",
        "    auc = roc_auc_score(y_test, y_prob)\n",
        "    print(\"AUC-ROC:\", round(auc, 4))\n"
      ],
      "metadata": {
        "id": "e6T9ycJmbqFE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "Nvd-uzx9cazi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from imblearn.over_sampling import SMOTE\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Separando treino e teste antes de aplicar SMOTE\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, stratify=y, random_state=42)\n",
        "\n",
        "# Aplicando SMOTE no conjunto de treino\n",
        "smote = SMOTE(random_state=42)\n",
        "X_train_res, y_train_res = smote.fit_resample(X_train, y_train)\n"
      ],
      "metadata": {
        "id": "NPJiUJiLcr6d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from xgboost import XGBClassifier\n",
        "\n",
        "# Treinando modelos com dados balanceados (SMOTE)\n",
        "modelo_rf_smote = RandomForestClassifier(random_state=42)\n",
        "modelo_rf_smote.fit(X_train_res, y_train_res)\n",
        "\n",
        "modelo_xgb_smote = XGBClassifier(random_state=42)\n",
        "modelo_xgb_smote.fit(X_train_res, y_train_res)\n",
        "\n"
      ],
      "metadata": {
        "id": "0xsewWuPcbPf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from xgboost import XGBClassifier\n",
        "\n",
        "# Random Forest com SMOTE\n",
        "modelo_rf_smote = RandomForestClassifier(random_state=42)\n",
        "modelo_rf_smote.fit(X_train_res, y_train_res)\n",
        "\n",
        "# XGBoost com SMOTE\n",
        "modelo_xgb_smote = XGBClassifier(use_label_encoder=False, eval_metric='logloss', random_state=42)\n",
        "modelo_xgb_smote.fit(X_train_res, y_train_res)\n"
      ],
      "metadata": {
        "id": "z_tirnExckRq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report, roc_auc_score, confusion_matrix, ConfusionMatrixDisplay\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Lista de modelos treinados com SMOTE\n",
        "modelos_smote = [\n",
        "    ('Random Forest (SMOTE)', modelo_rf_smote),\n",
        "    ('XGBoost (SMOTE)', modelo_xgb_smote)\n",
        "]\n",
        "\n",
        "# Avalia√ß√£o dos modelos\n",
        "for nome, modelo in modelos_smote:\n",
        "    print(f\"\\nModelo: {nome}\")\n",
        "\n",
        "    # Previs√µes\n",
        "    y_pred = modelo.predict(X_test)\n",
        "    y_prob = modelo.predict_proba(X_test)[:, 1]  # Probabilidades para AUC-ROC\n",
        "\n",
        "    # Relat√≥rio de classifica√ß√£o\n",
        "    print(classification_report(y_test, y_pred, digits=4))\n",
        "\n",
        "    # AUC-ROC\n",
        "    auc = roc_auc_score(y_test, y_prob)\n",
        "    print(f\"AUC-ROC: {auc:.4f}\")\n",
        "\n",
        "    # Matriz de confus√£o\n",
        "    cm = confusion_matrix(y_test, y_pred)\n",
        "    disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=modelo.classes_)\n",
        "    disp.plot(cmap=plt.cm.Blues)\n",
        "    plt.title(nome)\n",
        "    plt.show()\n"
      ],
      "metadata": {
        "id": "CxxNhtPhdH4K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        " * XGBoost teve ligeiramente melhor recall de fraudes, mas menor precis√£o.\n",
        "\n",
        "Random Forest teve melhor equil√≠brio geral (AUC, F1 e acur√°cia).\n",
        "\n",
        "A diferen√ßa de acertos totais √© pequena.\n",
        "\n",
        "* üí° Se o foco √© detectar mais fraudes mesmo errando um pouco mais (alto recall), o XGBoost pode ser preferido.\n",
        "Se o foco √© ter uma performance mais equilibrada, o Random Forest se destaca.\n"
      ],
      "metadata": {
        "id": "P62uv1DNdoU2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* An√°lise do Trade-off:\n",
        "* Precision vs. Recall: Embora a precision para a classe \"n√£o fraude\" seja muito boa, a recall da classe \"fraude\" precisa ser muito melhorada. Ou seja, o modelo √© conservador (n√£o identifica muitas fraudes) e perde a chance de bloquear muitas transa√ß√µes fraudulentas.\n",
        "\n",
        "* Custo das fraudes: Falsos negativos (fraudes n√£o identificadas) s√£o mais cr√≠ticos do que falsos positivos (compra leg√≠tima erradamente marcada como fraude). O preju√≠zo por fraude aprovada √© 100% do valor da compra, ent√£o, precisamos otimizar os modelos para identificar mais fraudes, mesmo que isso signifique reduzir a precis√£o."
      ],
      "metadata": {
        "id": "45y3do22ftf_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Ajuste do cutoff de decis√£o: Uma abordagem para melhorar o recall de fraudes seria ajustar o cutoff de probabilidade."
      ],
      "metadata": {
        "id": "ApXFS4s3f400"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# 1) Montar o df_test com tudo que precisamos\n",
        "df_test = X_test.copy()\n",
        "df_test['fraude'] = y_test.values\n",
        "# Traga o valor_compra do df original pelo mesmo √≠ndice\n",
        "df_test['valor_compra'] = df.loc[X_test.index, 'valor_compra']\n",
        "# Probabilidade de fraude segundo o modelo balanceado\n",
        "df_test['prob_rf'] = modelo_rf_smote.predict_proba(X_test)[:, 1]\n",
        "\n",
        "# 2) Fun√ß√£o de lucro l√≠quido\n",
        "def lucro_liquido(cutoff):\n",
        "    aprovadas = df_test[df_test['prob_rf'] < cutoff]\n",
        "    ganho = aprovadas.loc[aprovadas['fraude'] == 0, 'valor_compra'].sum() * 0.10\n",
        "    perda = aprovadas.loc[aprovadas['fraude'] == 1, 'valor_compra'].sum()\n",
        "    return ganho - perda\n",
        "\n",
        "# 3) Simular lucro para uma grade de cutoffs de 0 a 1\n",
        "thresholds = np.linspace(0, 1, 101)\n",
        "profits = [lucro_liquido(t) for t in thresholds]\n",
        "\n",
        "# 4) Encontrar o melhor cutoff\n",
        "best_i = int(np.argmax(profits))\n",
        "best_cutoff = thresholds[best_i]\n",
        "best_profit = profits[best_i]\n",
        "\n",
        "print(f\"üîé Melhor cutoff: {best_cutoff:.2f}\")\n",
        "print(f\"üí∞ Lucro l√≠quido estimado: R$ {best_profit:,.2f}\")\n",
        "\n",
        "# 5) Plotar Lucro vs Cutoff\n",
        "plt.figure(figsize=(8,5))\n",
        "plt.plot(thresholds, profits, marker='o')\n",
        "plt.axvline(best_cutoff, color='red', linestyle='--', label=f\"Cutoff √≥timo ({best_cutoff:.2f})\")\n",
        "plt.title('Lucro L√≠quido vs. Cutoff de Probabilidade de Fraude')\n",
        "plt.xlabel('Cutoff de Probabilidade')\n",
        "plt.ylabel('Lucro L√≠quido (R$)')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "SnqDlieLda5E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Regra de decis√£o: Ao bloquear todas as transa√ß√µes em que a probabilidade de fraude ‚â•¬†0.44, voc√™ maximiza o retorno financeiro.\n",
        "* Trade‚Äëoff: Esse ponto reflete um equil√≠brio em que voc√™ aprende a aceitar algumas fraudes (para n√£o perder compras leg√≠timas demais), mas bloqueia fraudes suficientes para gerar o maior lucro l√≠quido."
      ],
      "metadata": {
        "id": "E6QUDjLrgVuL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#classificando as transa√ß√µes com base na probabilidade de fraude,\n",
        "y_proba = modelo_rf_smote.predict_proba(X)[:,1]\n",
        "aprovar = (y_proba < 0.44)\n"
      ],
      "metadata": {
        "id": "5TyYPU5_gFri"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# üß† Insights Finais\n",
        "\n",
        "- Vari√°veis mais discriminativas\n",
        "\n",
        "- Entrega de documentos (entrega_doc_1): aus√™ncia de documento aumenta fortemente a probabilidade de fraude.\n",
        "\n",
        "- Scores operacionais (score_6, score_9, score_10, score_3): perfis de comportamento (‚Äúnotas‚Äù de confiabilidade) mostram diferen√ßas significativas entre fraudadores e clientes leg√≠timos.\n",
        "\n",
        "- Valor da compra: transa√ß√µes fraudulentas tendem a ter ticket m√©dio muito maior.\n",
        "\n",
        "- Modelagem e performance\n",
        "\n",
        "- Random Forest (SMOTE): melhor equil√≠brio geral (AUC‚ÄëROC 0.7475, Recall fraude 35.9%).\n",
        "\n",
        "- XGBoost (SMOTE): ligeiramente maior recall (38.7%) mas AUC‚ÄëROC um pouco menor (0.7379).\n",
        "\n",
        "- Regress√£o Log√≠stica: baixa capacidade de capturar fraudes (recall <¬†1%).\n",
        "\n",
        "Otimiza√ß√£o para o neg√≥cio\n",
        "\n",
        "Cutoff √≥timo de 0.44 sobre a probabilidade de fraude do Random Forest (SMOTE), que maximiza o lucro l√≠quido em R$¬†68.525,43 no conjunto de teste.\n",
        "\n",
        "Isso ajuda a decidir equilibra aprovar compras leg√≠timas (ganho de 10%) e bloquear fraudes (evitar perda de 100%).\n",
        "\n"
      ],
      "metadata": {
        "id": "t0LbBcZbhBYf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#_________________________________________________________________________________________________________________________________________________________#"
      ],
      "metadata": {
        "id": "dJyAfLW6h2L9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# üíº Sugest√£o ao Neg√≥cio\n",
        "\n",
        "* Implementar o modelo em produ√ß√£o\n",
        "\n",
        "Score em tempo real via API: para cada nova transa√ß√£o, calcular prob_fraude = modelo.predict_proba(...)[:,1].\n",
        "\n",
        "Regra de neg√≥cio: aprovar se prob_fraude < 0.44; caso contr√°rio, bloquear ou escalonar para an√°lise manual.\n",
        "\n",
        "* Monitoramento cont√≠nuo\n",
        "\n",
        "M√©tricas operacionais: acompanhar diariamente recall de fraude, ratio de aprova√ß√µes bloqueadas, receita gerada.\n",
        "\n",
        "Data‚Äëdrift: monitorar distribui√ß√£o de features (scores, valor_compra, entrega_doc_) para detectar mudan√ßas no perfil de fraude.\n",
        "\n",
        "* Ciclo de retroalimenta√ß√£o\n",
        "\n",
        "Feedback loop: incorporar rapidamente o resultado real (confirmado como fraude ou n√£o) para re-treinar o modelo periodicamente.\n",
        "\n",
        "- A/B testing de cutoffs: testar limiares ligeiramente diferentes (por exemplo, 0.40, 0.45) em grupos de controle para validar o cutoff √≥timo em produ√ß√£o.\n",
        "\n",
        "* Aprimorar features e cobertura\n",
        "\n",
        "- Explorar novas vari√°veis derivadas dos scores (combina√ß√µes, m√©dias ponderadas).\n",
        "\n",
        "- Incluir dados comportamentais (tempo de navega√ß√£o, device fingerprinting) se dispon√≠veis.\n",
        "\n",
        "# Governan√ßa e compliance\n",
        "\n",
        "Documentar todo o fluxo de dados e modelo para auditoria.\n",
        "\n",
        "Garantir explicabilidade usando SHAP para justificar bloqueios de transa√ß√µes, atendendo a requisitos regulat√≥rios.\n",
        "\n"
      ],
      "metadata": {
        "id": "tiwOub5EiDbG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ‚úÖ Pr√≥ximos passos recomendados:\n",
        "* Testar estabilidade do cutoff em diferentes splits ou per√≠odos (time split).\n",
        "\n",
        "* Monitorar performance no ambiente real, ajustando se houver drift de dados.\n",
        "\n",
        "* Avaliar impacto de novas features para tentar elevar ainda mais esse lucro."
      ],
      "metadata": {
        "id": "54Mj55uAg2tN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# üöÄ Deploy\n",
        "\n",
        "- Infraestrutura: containerizar o modelo (Docker) e exp√¥-lo via REST API (FastAPI ou Flask)\n",
        "\n",
        "- Lat√™ncia: garantir infer√™ncia em 200 ms por transa√ß√£o, priorizando predi√ß√£o em batch e em tempo real, se necess√°rio\n",
        "\n",
        "- Escalabilidade: usar orquestradores (Kubernetes) para suportar picos de demanda\n",
        "\n",
        "- Logging e alertas: capturar decis√µes, probabilidades, contexto da transa√ß√£o e acionar alertas para aumento s√∫bito de fraudes."
      ],
      "metadata": {
        "id": "-fzWVFs1juVb"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "JHa1WCIVkECg"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}